{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import fnmatch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from img_utils import ImgUtils\n",
    "from noise_scheduler import NoiseScheduler\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 1000/1000 [00:01<00:00, 554.41it/s]\n",
      "Resizing: 100%|██████████| 1000/1000 [00:00<00:00, 6099.27it/s]\n",
      "Casting: 100%|██████████| 1000/1000 [00:00<00:00, 4769.04it/s]\n",
      "Scaling: 100%|██████████| 1000/1000 [00:00<00:00, 1074.46it/s]\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "for dirpath, dirs, files in os.walk('Images'): \n",
    "  for filename in fnmatch.filter(files, '*.jpg'):\n",
    "    filenames.append(os.path.join(dirpath, filename))\n",
    "\n",
    "filenames = filenames[:1000] # only use first 100 images temporarily for quicker runtime\n",
    "\n",
    "imgs = [plt.imread(fn) for fn in tqdm(filenames, desc=\"Loading\")]\n",
    "imgs = [ImgUtils.resize_img(img, (256, 256)) for img in tqdm(imgs, desc=\"Resizing\")]\n",
    "imgs = [ImgUtils.int_to_float_img(img) for img in tqdm(imgs, desc=\"Casting\")]\n",
    "imgs = [ImgUtils.scale_img(img) for img in tqdm(imgs, desc=\"Scaling\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Noising:  14%|█▍        | 144/1000 [01:29<17:14,  1.21s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "n_timesteps = 100\n",
    "noiser = NoiseScheduler(n_timesteps, start=0.0001, end=0.06)\n",
    "\n",
    "training_inputs = []\n",
    "training_outputs = []\n",
    "for img in tqdm(imgs, desc=\"Noising\"):\n",
    "    for step in range(n_timesteps):\n",
    "        noised_img = noiser.forward(img, step)\n",
    "        training_inputs.append(noised_img)\n",
    "        noise = img - noised_img\n",
    "        training_outputs.append(noise)\n",
    "\n",
    "training_inputs = np.array(training_inputs)\n",
    "training_outputs = np.array(training_outputs)\n",
    "assert training_inputs.shape == training_outputs.shape == (len(imgs) * n_timesteps, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_imgs = [training_inputs[0], training_inputs[n_timesteps-1], \n",
    "                training_outputs[0], training_outputs[n_timesteps-1]]\n",
    "shown_imgs = [ImgUtils.unscale_img(img).clip(0,1) for img in chosen_imgs]\n",
    "ImgUtils.show_images(shown_imgs, cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet.new()\n",
    "unet.compile(optimizer=\"adam\", loss=lambda hx, y: (y-hx)**2)\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = unet.fit(training_inputs, training_outputs, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss over Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(1, 256, 256, 3) * 2 - 1\n",
    "new_dog = unet.predict(noise)[0]\n",
    "plt.imshow(ImgUtils.unscale_img(new_dog).clip(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
